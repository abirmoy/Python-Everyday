网络
神经网
神经网络
提取
的
特征
，
正常
情况
 
下
，
该
一维
特征
长度
应
与
最终
分类
的
类别
数
相同
。
如同
传统
机器
学习
的
步骤
一样
，
在
特
 
征
提取
后
，
需要
将
特征
送入
分类
分类器
。
在
卷积
神经
网络
神经网
神经网络
中
最
常用
的
分类
分类器
是
 
Softmax
 
分类
 
器
。
它
的
主要
功能
是
将
特征
特征值
转换
为
最终
分类
的
每个
类别
的
概率
值
。
训练
时如
公式
 
2.1
 
所示
，
其中
 
Z
 
为
输入
的
一维
特征
，
分类
的
总
类别
数为
 
N
，
softmax
(
K
)
求
的
就是
对应
真实
 
标注
类别
（
ground
-
truth
）
的
概率
。
在
网络
前向
运算
时
，
分类
分类器
输出
概率
结果
就是
最终
结果
了
，
而
在
网络
训练
的
时候
则
 
需要
额外
计算
损失
（
loss
）
。
通过
使用
随机
梯度
下降
（
Stochastic
 
Gradient
 
Descent
，
简称
 
SGD
）
等
方法
进行
损失
的
回传
，
才能
调整
网络
中
可
学习
参数
的
数值
，
达到
训练
网络
的
目的
。
在
卷积
神经
网络
神经网
神经网络
中
，
损失
大部
部分
大部分
计算
方式
如
公式
 
2.2
 
所示
是
在
由
分类
结果
的
概率
上
 
求
交叉
熵
（
cross
-
entropy
）
。
注意
由于
要
在
最后
分类
结果
的
概率
上求
交叉
熵
，
所以
损失
计
 
算层
必须
要
有
真实
标签
的
信息
。


2.1
.
8
经典
主干
网络
 
VGG
 


在
经过
前面
数
小节
关于
深度
学习
中
各层
的
介绍
后
，
本
节
介绍
一个
当前
被
众多
网络
作
 
为主
干
网络
的
 
VGG
 
网络
。
VGG
-
16
 
网络
结构
网络结构
示意
意图
示意图
见图
 
2.5
。
如前
文
所述
，
卷积
层
与
激活
函数
层
经常
组成
一个
共同
的
模块
，
每
经过
若干
这样
的
模
 
块
，
就
使用
下
采样
层
对
特征
进行
降维
处理
。
最后
当
特征
被
抽取
到
一定
程度
后
，
接入
全连
 
接层
，
最后
使用
 
Softmax
 
分类
分类器
得出
每个
类别
的
概率
。
为了
进行
算法
对比
，
很多
流行
算
 
法
包括
图像
分割
、
目标
检测
的
卷积
神经
网络
神经网
神经网络
都
采用
了
该
结构
作为
其
主干
结构
。




2.2
 
深度
学习
下
的
目标
检测
 


通过
以上
介绍
的
各种
层
的
组合
连接
形成
各种
网络
模型
，
应用
在
解决
各种
计算
算机
计算机
视觉
 
的
任务
中
。
文献

中
提出
的
目标
检测
网络
 
Faster
 
R
-
CNN
 
创新
创新性
的
提出
了
使用
卷积
神经
 
网络
提取
区域
提议